"""TF-IDF indekser dla RAG - optymalny dla polskiej terminologii matematycznej."""
import pickle
from pathlib import Path
from typing import List, Dict, Any, Optional
from dataclasses import dataclass

import numpy as np
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity

from data_loader import Chunk, load_all_chunks
from config import INDEX_DIR, TFIDF_INDEX_PATH, CHUNKS_PATH, TFIDF_NGRAM_RANGE, TFIDF_ANALYZER


# Polskie stop words (matematyczny kontekst)
POLISH_STOP_WORDS = [
    "i", "w", "na", "z", "do", "to", "≈ºe", "jest", "nie", "siƒô",
    "o", "co", "jak", "od", "po", "za", "ze", "ale", "tak", "dla",
    "by", "tego", "ten", "ta", "te", "tym", "tej", "tych", "sƒÖ",
    "byƒá", "zosta≈Ç", "kt√≥re", "kt√≥ry", "kt√≥ra", "lub", "albo",
    "te≈º", "jako", "np", "tzn", "itp", "etc", "mo≈ºe", "mo≈ºna",
    "gdy", "je≈õli", "oraz", "wiƒôc", "czy", "ka≈ºdy", "ka≈ºda",
    "wszystkie", "wszystkich", "bardzo", "tylko", "ju≈º", "jeszcze",
    "przy", "pod", "nad", "miƒôdzy", "przez", "przed", "oko≈Ço",
]


@dataclass
class SearchResult:
    """Wynik wyszukiwania RAG."""
    chunk_id: str
    score: float
    source: str
    category: str
    title: str
    content: str
    sympy_hint: str
    tips: str
    metadata: Dict[str, Any]

    def to_dict(self) -> dict:
        return {
            "id": self.chunk_id,
            "score": round(self.score, 4),
            "source": self.source,
            "category": self.category,
            "title": self.title,
            "content": self.content,
            "sympy_hint": self.sympy_hint,
            "tips": self.tips,
            "metadata": self.metadata,
        }


class TFIDFIndex:
    """TF-IDF indeks z cosine similarity do wyszukiwania chunk√≥w."""

    def __init__(self):
        self.vectorizer: Optional[TfidfVectorizer] = None
        self.tfidf_matrix = None
        self.chunks: List[Chunk] = []
        self._initialized = False

    def build(self, chunks: Optional[List[Chunk]] = None) -> None:
        """Zbuduj indeks TF-IDF z chunk√≥w."""
        if chunks is None:
            chunks = load_all_chunks()

        self.chunks = chunks
        texts = [c.to_search_text() for c in chunks]

        print(f"üî® Budowanie indeksu TF-IDF ({len(texts)} dokument√≥w)...")

        self.vectorizer = TfidfVectorizer(
            analyzer=TFIDF_ANALYZER,
            ngram_range=TFIDF_NGRAM_RANGE,
            max_features=50000,
            # stop_words nie dzia≈Ça z analyzer=char_wb, filtrujemy rƒôcznie w to_search_text()
            min_df=1,
            max_df=0.95,
            sublinear_tf=True,  # 1 + log(tf) ‚Äî lepsze dla d≈Çu≈ºszych dokument√≥w
        )

        self.tfidf_matrix = self.vectorizer.fit_transform(texts)
        self._initialized = True

        print(f"‚úÖ Indeks zbudowany: {self.tfidf_matrix.shape[0]} docs √ó {self.tfidf_matrix.shape[1]} features")

    def query(self, query_text: str, top_k: int = 3) -> List[SearchResult]:
        """Wyszukaj najbardziej pasujƒÖce chunki."""
        if not self._initialized:
            raise RuntimeError("Indeks nie jest zbudowany. Wywo≈Çaj build() najpierw.")

        query_vec = self.vectorizer.transform([query_text])
        similarities = cosine_similarity(query_vec, self.tfidf_matrix).flatten()

        # Top-K indeks√≥w
        top_indices = np.argsort(similarities)[-top_k:][::-1]

        results = []
        for idx in top_indices:
            score = float(similarities[idx])
            if score < 0.01:  # Odrzuƒá zbyt niskie wyniki
                continue

            chunk = self.chunks[idx]
            results.append(SearchResult(
                chunk_id=chunk.id,
                score=score,
                source=chunk.source,
                category=chunk.category,
                title=chunk.title,
                content=chunk.content[:500],  # Ogranicz d≈Çugo≈õƒá
                sympy_hint=chunk.sympy_hint,
                tips=chunk.tips,
                metadata=chunk.metadata,
            ))

        return results

    def save(self) -> None:
        """Zapisz indeks do plik√≥w."""
        INDEX_DIR.mkdir(parents=True, exist_ok=True)

        with open(TFIDF_INDEX_PATH, "wb") as f:
            pickle.dump({
                "vectorizer": self.vectorizer,
                "tfidf_matrix": self.tfidf_matrix,
            }, f)

        with open(CHUNKS_PATH, "wb") as f:
            pickle.dump(self.chunks, f)

        print(f"üíæ Indeks zapisany do {INDEX_DIR}")

    def load(self) -> bool:
        """Za≈Çaduj indeks z plik√≥w. Zwraca True je≈õli udane."""
        if not TFIDF_INDEX_PATH.exists() or not CHUNKS_PATH.exists():
            return False

        try:
            with open(TFIDF_INDEX_PATH, "rb") as f:
                data = pickle.load(f)
                self.vectorizer = data["vectorizer"]
                self.tfidf_matrix = data["tfidf_matrix"]

            with open(CHUNKS_PATH, "rb") as f:
                self.chunks = pickle.load(f)

            self._initialized = True
            print(f"üìÇ Indeks za≈Çadowany: {len(self.chunks)} chunk√≥w")
            return True
        except Exception as e:
            print(f"‚ö†Ô∏è  B≈ÇƒÖd ≈Çadowania indeksu: {e}")
            return False

    @property
    def is_ready(self) -> bool:
        return self._initialized

    @property
    def chunk_count(self) -> int:
        return len(self.chunks) if self._initialized else 0


def build_and_save_index() -> TFIDFIndex:
    """Zbuduj i zapisz indeks (one-shot)."""
    index = TFIDFIndex()
    index.build()
    index.save()
    return index


if __name__ == "__main__":
    # Zbuduj indeks i przetestuj
    idx = build_and_save_index()

    test_queries = [
        "r√≥wnanie kwadratowe z parametrem",
        "logarytm obliczanie warto≈õci",
        "pole tr√≥jkƒÖta trygonometria sinus",
        "prawdopodobie≈Ñstwo warunkowe Bayes",
        "pochodna optymalizacja warto≈õƒá najwiƒôksza",
        "ciƒÖg geometryczny suma niesko≈Ñczona",
        "dow√≥d indukcja matematyczna podzielno≈õƒá",
    ]

    for q in test_queries:
        print(f"\nüîç Query: '{q}'")
        results = idx.query(q, top_k=3)
        for r in results:
            print(f"  [{r.score:.3f}] {r.title} ({r.source})")
